# ğŸ“š EXPLICATION SIMPLE : LA CLASSIFICATION

## C'est quoi la Classification ?

---

## ğŸ¯ ANALOGIE SIMPLE

Imagine que tu es un **professeur qui doit corriger des copies** :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CLASSIFICATION = TRIER DES CHOSES EN CATÃ‰GORIES        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Exemple 1 : FRUITS
ğŸ Pomme    â†’ CatÃ©gorie : Rouge
ğŸŒ Banane   â†’ CatÃ©gorie : Jaune
ğŸŠ Orange   â†’ CatÃ©gorie : Orange

Exemple 2 : EMAILS
ğŸ“§ "FÃ©licitations, vous avez gagnÃ©!"  â†’ CatÃ©gorie : SPAM
ğŸ“§ "RÃ©union demain Ã  14h"             â†’ CatÃ©gorie : IMPORTANT
ğŸ“§ "Nouvelle newsletter"               â†’ CatÃ©gorie : PROMO

Exemple 3 : NOTRE PROJET
ğŸ’¬ "Nous allons amÃ©liorer la santÃ©"   â†’ CatÃ©gorie : POSITIF
ğŸ’¬ "Il y a une grave crise"           â†’ CatÃ©gorie : NÃ‰GATIF
ğŸ’¬ "La situation actuelle du pays"    â†’ CatÃ©gorie : NEUTRE
```

**Dans notre projet, on veut classer des PHRASES selon leur SENTIMENT !**

---

## ğŸ” DANS NOTRE PROJET : 2 MÃ‰THODES

### **MÃ‰THODE 1 : Rule-Based (Sans entraÃ®nement)**

C'est comme avoir une **liste de mots** et compter :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RULE-BASED = UTILISER DES RÃˆGLES PRÃ‰DÃ‰FINIES          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Ã‰TAPE 1 : On crÃ©e des listes de mots
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Mots POSITIFS :                          â”‚
â”‚ âœ… amÃ©liorer, dÃ©velopper, soutenir...   â”‚
â”‚                                          â”‚
â”‚ Mots NÃ‰GATIFS :                          â”‚
â”‚ âŒ problÃ¨me, crise, Ã©chec...             â”‚
â”‚                                          â”‚
â”‚ Mots NEUTRES :                           â”‚
â”‚ âšª situation, contexte, niveau...        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Ã‰TAPE 2 : On compte les mots dans la phrase
Phrase : "Nous allons amÃ©liorer et dÃ©velopper la santÃ©"
         âœ… amÃ©liorer (positif)
         âœ… dÃ©velopper (positif)
         â†’ 2 positifs, 0 nÃ©gatifs
         â†’ RÃ‰SULTAT : POSITIF âœ…

Phrase : "Il y a un grave problÃ¨me et une crise"
         âŒ problÃ¨me (nÃ©gatif)
         âŒ crise (nÃ©gatif)
         â†’ 0 positifs, 2 nÃ©gatifs
         â†’ RÃ‰SULTAT : NÃ‰GATIF âŒ

Ã‰TAPE 3 : Calcul du score
Score = (Positifs - NÃ©gatifs) / Total
```

**AVANTAGES :**
- âœ… Simple Ã  comprendre
- âœ… Rapide
- âœ… Pas besoin d'entraÃ®nement

**INCONVÃ‰NIENTS :**
- âŒ Ne comprend pas le contexte
- âŒ "pas bon" â†’ dÃ©tecte "bon" (positif) alors que c'est nÃ©gatif !

---

### **MÃ‰THODE 2 : Machine Learning SUPERVISÃ‰ (Avec entraÃ®nement)**

C'est comme **apprendre Ã  un enfant** avec des exemples :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ML SUPERVISÃ‰ = APPRENDRE Ã€ PARTIR D'EXEMPLES           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ANALOGIE : Apprendre Ã  un enfant Ã  reconnaÃ®tre des animaux

PHASE 1 : APPRENTISSAGE (Training)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tu montres des images avec rÃ©ponses :      â”‚
â”‚                                            â”‚
â”‚ ğŸ• â†’ "Chien"                               â”‚
â”‚ ğŸˆ â†’ "Chat"                                â”‚
â”‚ ğŸ¦ â†’ "Oiseau"                              â”‚
â”‚ ğŸ• â†’ "Chien"                               â”‚
â”‚ ğŸˆ â†’ "Chat"                                â”‚
â”‚ ... (20-30 exemples)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

AprÃ¨s avoir vu les exemples, l'enfant APPREND les patterns :
- 4 pattes + aboie = Chien
- 4 pattes + miaule = Chat
- 2 ailes + vole = Oiseau

PHASE 2 : TEST (Prediction)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tu montres une NOUVELLE image :            â”‚
â”‚ ğŸ• (qu'il n'a jamais vue)                  â”‚
â”‚                                            â”‚
â”‚ L'enfant dit : "C'est un CHIEN !"          â”‚
â”‚ â†’ Il a APPRIS Ã  gÃ©nÃ©raliser !              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¤– DANS NOTRE PROJET : CLASSIFICATION DE SENTIMENT

### **Ã‰TAPE 1 : CRÃ‰ER LE DATASET D'ENTRAÃNEMENT**

On donne des **exemples Ã©tiquetÃ©s** Ã  l'ordinateur :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DATASET = EXEMPLES AVEC RÃ‰PONSES                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

20 exemples POSITIFS :
âœ… "Nous allons amÃ©liorer la situation"         â†’ POSITIF
âœ… "Renforcer le systÃ¨me de santÃ©"              â†’ POSITIF
âœ… "DÃ©velopper l'emploi pour les jeunes"        â†’ POSITIF
âœ… "Garantir l'accÃ¨s Ã  l'Ã©ducation"             â†’ POSITIF
... (16 autres)

20 exemples NÃ‰GATIFS :
âŒ "ProblÃ¨me majeur dans le secteur"            â†’ NÃ‰GATIF
âŒ "Crise Ã©conomique grave"                     â†’ NÃ‰GATIF
âŒ "DifficultÃ©s importantes"                    â†’ NÃ‰GATIF
âŒ "Manque cruel de ressources"                 â†’ NÃ‰GATIF
... (16 autres)

20 exemples NEUTRES :
âšª "La situation actuelle du pays"              â†’ NEUTRE
âšª "Le contexte Ã©conomique national"            â†’ NEUTRE
âšª "Le niveau des indicateurs"                  â†’ NEUTRE
âšª "Le taux de croissance"                      â†’ NEUTRE
... (16 autres)

TOTAL : 60 exemples
```

---

### **Ã‰TAPE 2 : TRANSFORMER LES MOTS EN NOMBRES (Vectorisation)**

L'ordinateur ne comprend pas les mots, **seulement les nombres** !

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  VECTORISATION = TRANSFORMER TEXTE EN NOMBRES          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

MÃ‰THODE : TF-IDF (Term Frequency - Inverse Document Frequency)

Phrase : "amÃ©liorer la santÃ©"

Ã‰TAPE 1 : CrÃ©er un vocabulaire (tous les mots uniques)
Vocabulaire = [amÃ©liorer, santÃ©, problÃ¨me, crise, situation, ...]
               mot1      mot2    mot3      mot4    mot5

Ã‰TAPE 2 : Transformer la phrase en vecteur de nombres
"amÃ©liorer la santÃ©" â†’ [0.8, 0.6, 0.0, 0.0, 0.0, ...]
                        â†‘    â†‘    â†‘    â†‘    â†‘
                        mot1 mot2 mot3 mot4 mot5

Les nombres = importance du mot dans la phrase
- 0.8 = amÃ©liorer est TRÃˆS prÃ©sent
- 0.6 = santÃ© est prÃ©sent
- 0.0 = problÃ¨me n'est PAS prÃ©sent

EXEMPLE CONCRET :
Phrase 1 : "amÃ©liorer santÃ©"  â†’ [0.8, 0.6, 0.0, 0.0, 0.1, ...]
Phrase 2 : "problÃ¨me crise"   â†’ [0.0, 0.0, 0.9, 0.7, 0.0, ...]
Phrase 3 : "situation niveau" â†’ [0.0, 0.0, 0.0, 0.0, 0.6, ...]

Maintenant l'ordinateur peut calculer avec ces nombres !
```

---

### **Ã‰TAPE 3 : ENTRAÃNER LE MODÃˆLE**

On donne les **exemples + rÃ©ponses** Ã  3 algorithmes diffÃ©rents :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ENTRAÃNEMENT = L'ORDINATEUR APPREND LES PATTERNS      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

On teste 3 ALGORITHMES :

1ï¸âƒ£ NAIVE BAYES (Le Simple)
   Comment Ã§a marche :
   "Quelle est la probabilitÃ© que cette phrase soit positive
    sachant qu'elle contient le mot 'amÃ©liorer' ?"
   
   Calcul : P(Positif | "amÃ©liorer") = ?
   
   RÃ©sultat : 55% de prÃ©cision

2ï¸âƒ£ SVM (Le GÃ©omÃ¨tre) â­ GAGNANT !
   Comment Ã§a marche :
   "Je trace une LIGNE qui sÃ©pare les phrases positives
    des phrases nÃ©gatives dans l'espace"
   
   SchÃ©ma :
   
   Positif â—                      â— Positif
           â—                    â—
             â—                â—
               â”ƒ            â”ƒ  â† LIGNE SÃ‰PARATRICE
                 â—        â—
                   â—    â—
   NÃ©gatif         â—  â—              NÃ©gatif
   
   RÃ©sultat : 67% de prÃ©cision â† MEILLEUR !

3ï¸âƒ£ RANDOM FOREST (La ForÃªt)
   Comment Ã§a marche :
   "Je crÃ©e 100 arbres de dÃ©cision qui votent :
    Arbre 1 : Positif
    Arbre 2 : Positif
    Arbre 3 : NÃ©gatif
    ...
    â†’ MajoritÃ© vote Positif â†’ POSITIF"
   
   RÃ©sultat : 63% de prÃ©cision

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  VAINQUEUR : SVM avec 67% !            â”‚
â”‚  On garde ce modÃ¨le pour prÃ©dire       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### **Ã‰TAPE 4 : PRÃ‰DIRE SUR DE NOUVEAUX TEXTES**

Maintenant on peut classifier les 4 discours politiques :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PRÃ‰DICTION = UTILISER LE MODÃˆLE ENTRAÃNÃ‰              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PROCESSUS :

1. Prendre le discours du PAM
   Texte : "social parti santÃ© emploi programme dignitÃ©..."
   
2. DÃ©couper en petits segments (50 mots)
   Segment 1 : "social parti santÃ© emploi programme"
   Segment 2 : "dignitÃ© charge dirham entreprise"
   Segment 3 : "crÃ©ation permettre dÃ©veloppement"
   ... (12 segments au total)

3. Transformer chaque segment en nombres (TF-IDF)
   Segment 1 â†’ [0.3, 0.6, 0.2, 0.8, ...]
   Segment 2 â†’ [0.1, 0.0, 0.7, 0.3, ...]
   ...

4. Passer dans le modÃ¨le SVM entraÃ®nÃ©
   Segment 1 â†’ NEUTRE  âšª
   Segment 2 â†’ NEUTRE  âšª
   Segment 3 â†’ POSITIF âœ…
   Segment 4 â†’ NEUTRE  âšª
   ... (12 prÃ©dictions)

5. Calculer la distribution
   RÃ©sultats : 
   - 2 segments POSITIFS  (16.67%)
   - 1 segment NÃ‰GATIF    (8.33%)
   - 9 segments NEUTRES   (75.00%)

6. Calculer le score global
   Score = (Positifs - NÃ©gatifs) / Total
         = (16.67% - 8.33%)
         = +0.083
   
   â†’ RÃ‰SULTAT FINAL : NEUTRE âšª
```

---

## ğŸ“Š RÃ‰SULTATS CONCRETS DU PROJET

### **Comparaison Rule-Based vs ML EntraÃ®nÃ© :**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RÃ‰SULTATS POUR LES 4 PARTIS                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PARTI : PAM
â”œâ”€ Rule-Based  : POSITIF (+0.219)
â”‚  Logique : 18 mots positifs - 1 nÃ©gatif = POSITIF
â”‚
â””â”€ ML EntraÃ®nÃ© : NEUTRE (+0.083)
   Logique : 75% des segments classÃ©s neutres
   â†’ Le modÃ¨le est plus prudent et nuancÃ©

PARTI : PI
â”œâ”€ Rule-Based  : POSITIF (+0.222)
â”‚
â””â”€ ML EntraÃ®nÃ© : POSITIF (+0.246) âœ… CONCORDENT !
   â†’ Les 2 mÃ©thodes sont d'accord !

PARTI : PJD
â”œâ”€ Rule-Based  : POSITIF (+0.176)
â”‚
â””â”€ ML EntraÃ®nÃ© : NEUTRE (+0.118)
   â†’ Le modÃ¨le dÃ©tecte plus de nuances

PARTI : RNI
â”œâ”€ Rule-Based  : POSITIF (+0.269)
â”‚
â””â”€ ML EntraÃ®nÃ© : POSITIF (+0.421) âœ… CONCORDENT !
   â†’ ML donne un score PLUS positif !
   â†’ 47% de segments positifs dÃ©tectÃ©s
```

---

## ğŸ¯ POURQUOI 2 MÃ‰THODES ?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  COMPARAISON DES 2 MÃ‰THODES                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

RULE-BASED (Lexicon)
âœ… AVANTAGES :
   â€¢ Simple Ã  comprendre
   â€¢ Rapide (< 1 seconde)
   â€¢ InterprÃ©table (on sait POURQUOI)
   â€¢ Pas besoin de donnÃ©es d'entraÃ®nement

âŒ INCONVÃ‰NIENTS :
   â€¢ DÃ©pend de la qualitÃ© du dictionnaire
   â€¢ Ne comprend pas le contexte
   â€¢ "pas bon" â†’ dÃ©tecte "bon" (faux positif)

ML ENTRAÃNÃ‰ (SVM)
âœ… AVANTAGES :
   â€¢ Apprend automatiquement les patterns
   â€¢ Comprend mieux le contexte
   â€¢ Plus nuancÃ© dans les prÃ©dictions
   â€¢ Peut s'amÃ©liorer avec plus d'exemples

âŒ INCONVÃ‰NIENTS :
   â€¢ Plus lent (~3 secondes)
   â€¢ Moins interprÃ©table (boÃ®te noire)
   â€¢ NÃ©cessite des exemples d'entraÃ®nement
   â€¢ PrÃ©cision dÃ©pend de la qualitÃ© des exemples

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CONCLUSION :                              â”‚
â”‚  On utilise les 2 pour COMPARER !          â”‚
â”‚  Si elles sont d'accord â†’ confiance forte  â”‚
â”‚  Si elles divergent â†’ vÃ©rification manuelleâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”¢ LES CHIFFRES EXPLIQUÃ‰S

### **67% de prÃ©cision, c'est bien ?**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  INTERPRÃ‰TATION DE LA PRÃ‰CISION                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

67% = Le modÃ¨le a RAISON 67 fois sur 100

Contexte :
â€¢ 33% = Hasard (3 classes : positif/nÃ©gatif/neutre)
â€¢ 50% = ModÃ¨le mÃ©diocre
â€¢ 67% = BON modÃ¨le âœ…
â€¢ 80% = TrÃ¨s bon modÃ¨le
â€¢ 90% = Excellent (rare sans beaucoup de donnÃ©es)

Notre 67% avec seulement 60 exemples = CORRECT ! âœ…

Pour amÃ©liorer Ã  80%+ :
â†’ Il faudrait 200-500 exemples d'entraÃ®nement
```

---

## ğŸ’¡ SCHÃ‰MA RÃ‰CAPITULATIF COMPLET

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           CLASSIFICATION DE SENTIMENT                      â”‚
â”‚              (Tout le processus)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1ï¸âƒ£ PRÃ‰PARATION
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ 60 exemples Ã©tiquetÃ©s            â”‚
   â”‚ 20 positifs + 20 nÃ©gatifs +      â”‚
   â”‚ 20 neutres                       â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
2ï¸âƒ£ VECTORISATION (TF-IDF)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ "amÃ©liorer santÃ©"                â”‚
   â”‚ â†’ [0.8, 0.6, 0.0, ...]          â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
3ï¸âƒ£ SPLIT TRAIN/TEST
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ 75% Train (45 exemples)          â”‚
   â”‚ 25% Test (15 exemples)           â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
4ï¸âƒ£ ENTRAÃNEMENT
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Naive Bayes â†’ 55%                â”‚
   â”‚ SVM â†’ 67% â­ GAGNANT             â”‚
   â”‚ Random Forest â†’ 63%              â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
5ï¸âƒ£ SAUVEGARDE
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ modele_sentiment.pkl             â”‚
   â”‚ vectorizer_sentiment.pkl         â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
6ï¸âƒ£ PRÃ‰DICTION SUR NOUVEAUX TEXTES
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Discours PAM â†’ NEUTRE (+0.083)   â”‚
   â”‚ Discours PI â†’ POSITIF (+0.246)   â”‚
   â”‚ Discours PJD â†’ NEUTRE (+0.118)   â”‚
   â”‚ Discours RNI â†’ POSITIF (+0.421)  â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ POUR TA PRÃ‰SENTATION

### **Explication en 1 minute :**

> "La classification, c'est comme **trier des emails en catÃ©gories** (spam, important, promo).
> 
> Dans notre projet, on **trie des phrases selon leur sentiment** : positif, nÃ©gatif ou neutre.
> 
> J'ai utilisÃ© **2 mÃ©thodes** :
> 
> **MÃ©thode 1 - Rule-Based :** Je compte les mots positifs et nÃ©gatifs dans une liste. Simple mais limitÃ©.
> 
> **MÃ©thode 2 - Machine Learning :** J'ai crÃ©Ã© **60 exemples Ã©tiquetÃ©s** (20 positifs, 20 nÃ©gatifs, 20 neutres) pour **entraÃ®ner un modÃ¨le**. Le modÃ¨le apprend tout seul Ã  reconnaÃ®tre les patterns, comme on apprend Ã  un enfant Ã  reconnaÃ®tre des animaux.
> 
> J'ai testÃ© **3 algorithmes** : Naive Bayes, SVM et Random Forest. **SVM a gagnÃ© avec 67% de prÃ©cision**.
> 
> Les 2 mÃ©thodes **concordent sur PI et RNI** (positifs), ce qui valide les rÃ©sultats !"

---

## â“ QUESTIONS FRÃ‰QUENTES

**Q : Pourquoi seulement 60 exemples ?**  
R : C'est suffisant pour une dÃ©monstration. Pour un systÃ¨me professionnel, il faudrait 500-1000 exemples.

**Q : Pourquoi SVM a gagnÃ© ?**  
R : SVM trouve le meilleur "mur" qui sÃ©pare les classes dans un espace mathÃ©matique. C'est trÃ¨s efficace pour les petits datasets.

**Q : C'est quoi TF-IDF ?**  
R : Term Frequency - Inverse Document Frequency. Ã‡a transforme les mots en nombres en valorisant les mots importants et rares.

**Q : 67%, c'est bien ?**  
R : Oui ! Avec 60 exemples seulement, c'est un bon rÃ©sultat. Le hasard donnerait 33%.

**Q : Pourquoi les 2 mÃ©thodes divergent parfois ?**  
R : Elles utilisent des logiques diffÃ©rentes. Quand elles concordent â†’ confiance forte. Quand elles divergent â†’ le texte est nuancÃ©.

---

## âœ… RÃ‰CAPITULATIF FINAL

```
CLASSIFICATION = TRIER EN CATÃ‰GORIES

Dans notre projet :
â”œâ”€ OBJECTIF : Classer phrases en Positif/NÃ©gatif/Neutre
â”‚
â”œâ”€ MÃ‰THODE 1 : Rule-Based
â”‚  â””â”€ Compte les mots dans des listes
â”‚
â”œâ”€ MÃ‰THODE 2 : ML EntraÃ®nÃ© (SVM)
â”‚  â”œâ”€ 60 exemples d'entraÃ®nement
â”‚  â”œâ”€ Vectorisation TF-IDF
â”‚  â”œâ”€ 3 algorithmes testÃ©s
â”‚  â”œâ”€ SVM gagnant (67%)
â”‚  â””â”€ ModÃ¨le sauvegardÃ©
â”‚
â””â”€ RÃ‰SULTATS :
   â”œâ”€ PI : Positif (les 2 concordent) âœ…
   â”œâ”€ RNI : Positif (les 2 concordent) âœ…
   â”œâ”€ PAM : Divergence (Pos vs Neu)
   â””â”€ PJD : Divergence (Pos vs Neu)
```

---

**C'est plus clair maintenant ? ğŸ˜Š**

**Des questions sur un point spÃ©cifique ?**

