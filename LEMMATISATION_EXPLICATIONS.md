# üî¨ Lemmatisation : Technique Avanc√©e de Text Mining

## üìå Qu'est-ce que la Lemmatisation ?

La **lemmatisation** est une technique de normalisation linguistique qui r√©duit chaque mot √† sa **forme canonique** (ou lemme), c'est-√†-dire sa forme de base telle qu'elle appara√Æt dans un dictionnaire.

### Exemples concrets :
| Mot original | Lemme |
|-------------|-------|
| `d√©veloppons` | `d√©velopper` |
| `d√©veloppement` | `d√©veloppement` |
| `d√©velopp√©` | `d√©velopper` |
| `politique` | `politique` |
| `politiques` | `politique` |
| `gouvernemental` | `gouvernemental` |
| `gouverner` | `gouverner` |

---

## üÜö Diff√©rence avec la **Stemming** (Racinisation)

| Technique | M√©thode | R√©sultat | Exemple |
|-----------|---------|----------|---------|
| **Stemming** | Coupe la fin des mots selon des r√®gles | Racine approximative (pas toujours un vrai mot) | `d√©veloppement` ‚Üí `develop` |
| **Lemmatisation** | Analyse morphologique avec dictionnaire | Lemme valide (vrai mot) | `d√©veloppement` ‚Üí `d√©veloppement` |

### Pourquoi la lemmatisation est meilleure ?
- ‚úÖ **Pr√©cision linguistique** : Produit des vrais mots
- ‚úÖ **Contexte grammatical** : Tient compte du r√¥le du mot (verbe, nom, etc.)
- ‚úÖ **Qualit√© d'analyse** : R√©sultats plus pertinents et interpr√©tables

---

## üöÄ Impl√©mentation dans notre projet

### Biblioth√®que utilis√©e : **spaCy**
[spaCy](https://spacy.io/) est une biblioth√®que NLP (Natural Language Processing) moderne et performante.

**Mod√®le utilis√©** : `fr_core_news_sm` (fran√ßais)
- Mod√®le pr√©-entra√Æn√© sur des textes d'actualit√© fran√ßais
- Contient un dictionnaire de lemmes et des r√®gles grammaticales

### Installation :
```bash
pip install spacy
python -m spacy download fr_core_news_sm
```

---

## üìä Impact sur notre analyse

### R√©sultats de la r√©duction :

| Parti | Mots bruts | Lemmes extraits | R√©duction |
|-------|-----------|----------------|-----------|
| **PAM** | 1,067 | **535** | 50% |
| **PI** | 5,370 | **2,492** | 54% |
| **PJD** | 1,605 | **746** | 54% |
| **RNI** | 1,688 | **858** | 49% |

**Moyenne : 52% de r√©duction** ‚Üí *Concentration sur les concepts cl√©s*

---

## üéØ Avantages pour l'analyse th√©matique

### Avant la lemmatisation :
```
d√©velopper (10 fois)
d√©veloppement (8 fois)
d√©veloppons (3 fois)
‚Üí 3 entr√©es distinctes = analyse fragment√©e
```

### Apr√®s la lemmatisation :
```
d√©velopper (21 fois)
‚Üí 1 seule entr√©e = vision unifi√©e du concept
```

---

## üîç Processus de lemmatisation dans le code

```python
# Chargement du mod√®le fran√ßais
nlp = spacy.load("fr_core_news_sm")

# Traitement du texte
doc = nlp(texte)

# Extraction des lemmes
for token in doc:
    if not token.is_stop and len(token.lemma_) > 2:
        lemmes.append(token.lemma_.lower())
```

### Filtres appliqu√©s :
1. **Suppression des stopwords** (mots vides : `le, la, de, un, etc.`)
2. **Suppression de la ponctuation**
3. **Longueur minimale** : 3 caract√®res
4. **Normalisation** : minuscules

---

## üìà Am√©lioration de la qualit√©

### 1. Nuages de mots plus coh√©rents
Sans lemmatisation : `d√©velopper`, `d√©veloppement`, `d√©velopp√©` apparaissent s√©par√©ment

Avec lemmatisation : Un seul concept `d√©velopper` avec une taille proportionnelle √† l'importance r√©elle

### 2. Analyse de co-occurrence plus pr√©cise
Les th√®mes sont mieux identifi√©s car les variantes d'un m√™me mot sont regroup√©es

### 3. R√©sultats plus professionnels
L'analyse refl√®te vraiment les **concepts abord√©s**, pas juste les mots utilis√©s

---

## üõ†Ô∏è Techniques compl√©mentaires appliqu√©es

| Technique | Objectif | Outil utilis√© |
|-----------|----------|---------------|
| **Tokenisation** | D√©couper le texte en mots | spaCy |
| **Nettoyage** | Supprimer chiffres et ponctuation | Regex (`re`) |
| **Stopwords** | √âliminer mots vides | spaCy (liste int√©gr√©e) |
| **Lemmatisation** | R√©duire aux formes de base | spaCy NLP |

---

## üåü R√©sultat final

La **lemmatisation** transforme une analyse basique en une **√©tude linguistique professionnelle**, donnant des r√©sultats :
- ‚úÖ Plus pr√©cis
- ‚úÖ Plus compacts
- ‚úÖ Plus interpr√©tables
- ‚úÖ Plus fiables pour la prise de d√©cision

---

## üìö R√©f√©rences

- [Documentation spaCy](https://spacy.io/)
- [Mod√®les fran√ßais spaCy](https://spacy.io/models/fr)
- [Lemmatisation vs Stemming](https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html)

