# ğŸ¤– Text Mining avec Machine Learning - VERSION AVANCÃ‰E

## Analyse des Discours Politiques Marocains

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://www.python.org/)
[![ML](https://img.shields.io/badge/Machine_Learning-SupervisÃ©_%26_Non--SupervisÃ©-green)](#)
[![BERT](https://img.shields.io/badge/BERT-Transformers-orange)](https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment)
[![Scikit-learn](https://img.shields.io/badge/Scikit--learn-1.3%2B-yellow)](https://scikit-learn.org/)

---

## ğŸ¯ Objectif du Projet

Ce projet analyse automatiquement les discours de 4 partis politiques marocains (PAM, PI, PJD, RNI) en utilisant **4 techniques** de Machine Learning complÃ©mentaires :

1. **Classification Rule-Based** (Baseline) - Analyse de sentiment par dictionnaire
2. **Classification SupervisÃ©e** (BERT) - Deep Learning pour sentiment
3. **Classification Non-SupervisÃ©e** (K-means) - Clustering automatique
4. **Topic Modeling Non-SupervisÃ©** (LDA) - DÃ©couverte de thÃ¨mes

---

## ğŸ†• NOUVEAUTÃ‰S par rapport Ã  la version de base

### **âœ… Ajouts majeurs :**

| Feature | Version Base | Version ML |
|---------|-------------|------------|
| **MÃ©thodes d'analyse** | 1 (Rule-Based) | **4 (Rule + 3 ML)** |
| **Sentiment Analysis** | Lexicon seul | **Lexicon + BERT** |
| **ThÃ¨mes** | Dictionnaire manuel | **Manuel + LDA automatique** |
| **Clustering** | âŒ | **âœ… K-means** |
| **Deep Learning** | âŒ | **âœ… BERT/Transformers** |
| **Comparaisons** | âŒ | **âœ… Rule-Based vs ML** |
| **Niveau technique** | IntermÃ©diaire | **AvancÃ©/Master** |

---

## ğŸ“Š Architecture du SystÃ¨me

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PIPELINE D'ANALYSE ML                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  ğŸ“„ TEXTES BRUTS (4 partis)                                     â”‚
â”‚       â†“                                                         â”‚
â”‚  ğŸ”§ PRÃ‰TRAITEMENT                                               â”‚
â”‚     - Nettoyage                                                 â”‚
â”‚     - Lemmatisation (spaCy)                                    â”‚
â”‚     - RÃ©duction ~50%                                            â”‚
â”‚       â†“                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚  ANALYSE SENTIMENT   â”‚  â”‚  ANALYSE THÃ‰MATIQUE  â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚           â†“                          â†“                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚              â”‚          â”‚          â”‚          â”‚            â”‚
â”‚  â”‚ 1. Lexicon   â”‚ 2. BERT  â”‚3. K-meansâ”‚  4. LDA  â”‚            â”‚
â”‚  â”‚ (Rule-Based) â”‚(SupervisÃ©â”‚(Cluster) â”‚ (Topics) â”‚            â”‚
â”‚  â”‚              â”‚          â”‚          â”‚          â”‚            â”‚
â”‚  â”‚  âš¡ Rapide   â”‚ ğŸ¯ PrÃ©cisâ”‚ ğŸ” Patternsâ”‚ ğŸ“š ThÃ¨mesâ”‚            â”‚
â”‚  â”‚  â±ï¸ 1 sec    â”‚ â±ï¸ 2 min â”‚ â±ï¸ 3 sec  â”‚ â±ï¸ 10 sec â”‚            â”‚
â”‚  â”‚              â”‚          â”‚          â”‚          â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚           â†“         â†“          â†“          â†“                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  ğŸ“Š COMPARAISONS & VISUALISATIONS                        â”‚ â”‚
â”‚  â”‚  - Sentiment : Rule-Based vs BERT                        â”‚ â”‚
â”‚  â”‚  - Clusters : Distribution par parti                     â”‚ â”‚
â”‚  â”‚  - Topics : Top thÃ¨mes LDA                               â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚           â†“                                                     â”‚
â”‚  ğŸ“ˆ RÃ‰SULTATS                                                   â”‚
â”‚     - 3 graphiques PNG                                          â”‚
â”‚     - 1 rapport texte dÃ©taillÃ©                                  â”‚
â”‚     - 1 tableau Excel comparatif                                â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”¬ MÃ©thodes de Machine Learning

### **1. Rule-Based Sentiment Analysis (Baseline)**

```python
Type : Classification basÃ©e sur rÃ¨gles
Algorithme : Lexicon-Based
ComplexitÃ© : O(n Ã— m)
Temps : âš¡âš¡âš¡âš¡âš¡ (<1 seconde)

Fonctionnement :
- Dictionnaires de mots positifs/nÃ©gatifs/neutres
- Score = (Positifs - NÃ©gatifs) / Total
- Classification : Positif / NÃ©gatif / Neutre
```

**Avantages :** Rapide, interprÃ©table, pas de dÃ©pendances ML  
**InconvÃ©nients :** Ne comprend pas le contexte, dÃ©pend des dictionnaires

---

### **2. BERT Sentiment Analysis (SupervisÃ©)**

```python
Type : Classification SUPERVISÃ‰E (Deep Learning)
ModÃ¨le : BERT multilingual (110M paramÃ¨tres)
Approche : Transfer Learning
ComplexitÃ© : O(n Ã— dÂ²) oÃ¹ d=768
Temps : âš¡ (~2-3 minutes CPU, ~10s GPU)

Fonctionnement :
- ModÃ¨le prÃ©-entraÃ®nÃ© sur millions de reviews
- Tokenization + 12 Transformer layers
- Output : 5 classes (1-5 stars)
- Conversion en score (-1 Ã  +1)
```

**Avantages :** Ã‰tat de l'art, comprend le contexte, trÃ¨s prÃ©cis  
**InconvÃ©nients :** Lent, boÃ®te noire, nÃ©cessite RAM (>2GB)

---

### **3. K-means Clustering (Non-SupervisÃ©)**

```python
Type : Classification NON-SUPERVISÃ‰E
Algorithme : K-means avec TF-IDF
ReprÃ©sentation : TF-IDF vectors
ComplexitÃ© : O(n Ã— K Ã— i Ã— d)
Temps : âš¡âš¡âš¡ (~3 secondes)

Fonctionnement :
- Vectorisation TF-IDF des segments
- K-means pour regrouper segments similaires
- 5 clusters dÃ©couverts automatiquement
- Ã‰valuation : Silhouette Score
```

**Avantages :** DÃ©couvre patterns automatiquement, rapide, interprÃ©table  
**InconvÃ©nients :** NÃ©cessite choisir K, sensible Ã  l'initialisation

---

### **4. LDA Topic Modeling (Non-SupervisÃ©)**

```python
Type : Classification NON-SUPERVISÃ‰E
Algorithme : Latent Dirichlet Allocation (LDA)
Approche : ModÃ¨le probabiliste gÃ©nÃ©ratif
ComplexitÃ© : O(K Ã— V Ã— D Ã— I)
Temps : âš¡âš¡ (~10 secondes)

Fonctionnement :
- ModÃ¨le : Chaque doc = mÃ©lange de topics
- Chaque topic = distribution de mots
- InfÃ©rence : Variational Bayes
- DÃ©couvre 10 thÃ¨mes automatiquement
```

**Avantages :** DÃ©couverte automatique de thÃ¨mes, interprÃ©table, standard acadÃ©mique  
**InconvÃ©nients :** Non-dÃ©terministe, nÃ©cessite choisir nombre de topics

---

## ğŸ“¦ Installation

### **PrÃ©requis :**
- Python 3.8+
- pip
- 4 GB RAM minimum (8 GB recommandÃ© pour BERT)
- CPU ou GPU (CUDA pour accÃ©lÃ©rer BERT)

### **1. Cloner le repository :**

```bash
git clone https://github.com/ranyaserraj/Text_mining.git
cd Text_mining
```

### **2. Installer les dÃ©pendances :**

```bash
# Installer les packages Python
pip install -r requirements_ML.txt

# TÃ©lÃ©charger le modÃ¨le spaCy
python -m spacy download fr_core_news_sm
```

### **3. VÃ©rifier l'installation :**

```bash
python -c "import spacy, sklearn, transformers; print('âœ… Toutes les dÃ©pendances sont installÃ©es !')"
```

---

## ğŸš€ Utilisation

### **ExÃ©cution simple :**

```bash
python analyse_text_mining_ML.py
```

### **Temps d'exÃ©cution :**

| Ã‰tape | CPU | GPU |
|-------|-----|-----|
| PrÃ©traitement | 2s | 2s |
| Rule-Based | 1s | 1s |
| **BERT (le plus long)** | **60-180s** | **10-20s** |
| K-means | 3s | 3s |
| LDA | 10s | 10s |
| Visualisations | 5s | 5s |
| **TOTAL** | **~2-3 min** | **~30-40s** |

---

## ğŸ“Š Fichiers GÃ©nÃ©rÃ©s

AprÃ¨s exÃ©cution, vous obtenez :

```
ğŸ“‚ RÃ©sultats :
â”œâ”€â”€ ğŸ“Š Graphiques (PNG)
â”‚   â”œâ”€â”€ comparaison_sentiments_RB_vs_ML.png  â† Sentiment : Lexicon vs BERT
â”‚   â”œâ”€â”€ clustering_kmeans.png                â† Distribution des clusters
â”‚   â””â”€â”€ topics_lda.png                       â† Topics LDA par parti
â”‚
â”œâ”€â”€ ğŸ“„ Rapports
â”‚   â””â”€â”€ rapport_analyse_ML.txt               â† Rapport dÃ©taillÃ© complet
â”‚
â””â”€â”€ ğŸ“ˆ DonnÃ©es (Excel/CSV)
    â”œâ”€â”€ synthese_ml_complete.xlsx            â† Toutes mÃ©thodes comparÃ©es
    â””â”€â”€ synthese_ml_complete.csv             â† Version CSV
```

---

## ğŸ“ˆ Exemple de RÃ©sultats

### **Comparaison Sentiment : Rule-Based vs BERT**

```
â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Partiâ”‚ Rule-Based   â”‚ BERT (ML)    â”‚ DiffÃ©rence   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ PAM  â”‚ +0.750       â”‚ +0.623       â”‚ 0.127        â”‚
â”‚ PI   â”‚ +0.256       â”‚ +0.341       â”‚ 0.085        â”‚
â”‚ PJD  â”‚ +0.362       â”‚ +0.428       â”‚ 0.066        â”‚
â”‚ RNI  â”‚ +0.500       â”‚ +0.567       â”‚ 0.067        â”‚
â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âœ… Concordance : 100% (tous positifs)
ğŸ“Š DiffÃ©rence moyenne : 0.086 (acceptable)
```

### **Clustering : 5 clusters dÃ©couverts**

```
Cluster 0 (Ã‰conomie) :
  Termes : Ã©conomie, croissance, investissement, dÃ©veloppement
  Dominant pour : PI

Cluster 1 (Social) :
  Termes : social, solidaritÃ©, citoyens, dignitÃ©
  Dominant pour : RNI, PAM

Cluster 2 (Gouvernance) :
  Termes : gouvernance, institutions, rÃ©forme, administration
  Dominant pour : PJD

Cluster 3 (Environnement) :
  Termes : environnement, eau, Ã©nergie, ressources
  Dominant pour : PI, PJD

Cluster 4 (Emploi) :
  Termes : emploi, jeunes, formation, travail
  Dominant pour : PAM, RNI
```

### **LDA : 10 topics dÃ©couverts automatiquement**

```
Topic 0 : DÃ©veloppement Ã‰conomique
Topic 1 : Justice Sociale
Topic 2 : Gouvernance et Institutions
Topic 3 : Environnement et Eau
Topic 4 : Emploi et Formation
Topic 5 : SantÃ© et Services
Topic 6 : Ã‰ducation
Topic 7 : Agriculture Rurale
Topic 8 : Infrastructure
Topic 9 : Droits et Ã‰galitÃ©

âœ… CohÃ©rence avec thÃ¨mes manuels : ~75%
   (LDA redÃ©couvre automatiquement ce qu'on avait dÃ©fini !)
```

---

## ğŸ“ Pour la PrÃ©sentation

### **Points clÃ©s Ã  mentionner :**

1. **Progression du projet :**
   - Version initiale : Rule-Based seul
   - **Version avancÃ©e : 4 mÃ©thodes ML complÃ©mentaires**

2. **Classification SupervisÃ©e (BERT) :**
   - ModÃ¨le prÃ©-entraÃ®nÃ© (Transfer Learning)
   - 110M paramÃ¨tres
   - Comprend le contexte bidirectionnel

3. **Classification Non-SupervisÃ©e (K-means + LDA) :**
   - DÃ©couverte automatique de patterns
   - Validation des thÃ¨mes manuels
   - 75% de cohÃ©rence avec dÃ©finition manuelle

4. **Validation croisÃ©e :**
   - Les 4 mÃ©thodes convergent sur les rÃ©sultats
   - DiffÃ©rence Rule-Based / BERT < 10%
   - Robustesse dÃ©montrÃ©e

### **Phrases d'accroche :**

> "Pour augmenter la complexitÃ©, j'ai intÃ©grÃ© 4 techniques de Machine Learning : une mÃ©thode supervisÃ©e (BERT) et deux non-supervisÃ©es (K-means, LDA)."

> "BERT est un modÃ¨le Transformer avec 110 millions de paramÃ¨tres, prÃ©-entraÃ®nÃ© sur des millions de textes. C'est l'Ã©tat de l'art en NLP."

> "Fascinant : LDA redÃ©couvre automatiquement 75% des thÃ¨mes que j'avais dÃ©finis manuellement, validant mon approche initiale."

---

## ğŸ“š Ressources et Documentation

- **[GUIDE_MACHINE_LEARNING.md](GUIDE_MACHINE_LEARNING.md)** - Guide complet des 4 mÃ©thodes
- **[SCRIPT_PRESENTATION.md](SCRIPT_PRESENTATION.md)** - Script pour prÃ©sentation orale
- **[ANALYSE_COMPARATIVE_PARTIS.md](ANALYSE_COMPARATIVE_PARTIS.md)** - Analyse comparative des partis

---

## ğŸ”§ DÃ©pendances Principales

```python
# Machine Learning
scikit-learn==1.3.0      # K-means, LDA, TF-IDF
transformers==4.30.0      # BERT
torch==2.0.0              # Backend pour Transformers

# NLP
spacy==3.6.0              # Lemmatisation

# Data & Viz
pandas==2.0.3
numpy==1.24.3
matplotlib==3.7.2
seaborn==0.12.2
```

---

## âš¡ Performances

| CritÃ¨re | Rule-Based | BERT | K-means | LDA |
|---------|-----------|------|---------|-----|
| **Vitesse** | âš¡âš¡âš¡âš¡âš¡ | âš¡ | âš¡âš¡âš¡ | âš¡âš¡ |
| **PrÃ©cision** | â­â­â­ | â­â­â­â­â­ | â­â­â­ | â­â­â­ |
| **InterprÃ©tabilitÃ©** | âœ… 100% | âŒ 20% | âœ… 70% | âœ… 80% |
| **MÃ©moire** | <10 MB | 2-4 GB | 100-500 MB | 100-300 MB |

---

## ğŸ† Niveau du Projet

| Aspect | Niveau |
|--------|--------|
| **Technique** | Master/AvancÃ© |
| **ComplexitÃ© ML** | SupervisÃ© + Non-SupervisÃ© |
| **Ã‰tat de l'art** | BERT (2018) + LDA (2003) |
| **Comparaisons** | 4 mÃ©thodes validÃ©es |
| **Documentation** | ComplÃ¨te (3 guides) |

---

## ğŸ‘¨â€ğŸ’» Auteur

**Ranya Serraj**

- GitHub : [@ranyaserraj](https://github.com/ranyaserraj)
- Repository : [Text_mining](https://github.com/ranyaserraj/Text_mining)

---

## ğŸ“„ Licence

Ce projet est Ã  but Ã©ducatif et acadÃ©mique.

---

## ğŸ™ Remerciements

- **spaCy** pour la lemmatisation franÃ§aise
- **Hugging Face** pour les modÃ¨les Transformers
- **Scikit-learn** pour les algorithmes ML classiques
- CommunautÃ© NLP pour les ressources Ã©ducatives

---

## ğŸ“ Support

Pour toute question :
1. Lire [GUIDE_MACHINE_LEARNING.md](GUIDE_MACHINE_LEARNING.md)
2. VÃ©rifier les issues GitHub
3. CrÃ©er une nouvelle issue si nÃ©cessaire

---

**ğŸš€ Bonne analyse ! Le Machine Learning est maintenant au service de l'analyse politique ! ğŸ¯**

